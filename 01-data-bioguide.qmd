---
title: 01-data-bioguide
author: Gayoung Kim
format: 
    html:
        code-fold: false
        toc: true
---

This is a notebook for (1) data acquisition and (2) data cleaning for the historical archive data of U.S. Congress members biography data.

## Setup

```{python}
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import re
from collections import defaultdict
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
```

```{python}
# Configuration
RAW_DATA_DIR = Path("data/raw")
OUTPUT_DIR = Path("data/processed")
TEMP_DIR = Path("data/temp")

# Create directories if directories do not exist
for dir_path in [OUTPUT_DIR, TEMP_DIR, RAW_DATA_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)
```

## Load Data

```{python}
def load_all_bioguide_files(directory: Path) -> pd.DataFrame:
    """
    Load all bioguide JSON files from a directory.
    
    Parameters
    ----------
    directory : Path
        Directory containing bioguide JSON files
        
    Returns
    -------
    pd.DataFrame
        Combined bioguide data
    """
    all_records = []
    json_files = list(directory.glob("*.json"))
    
    print(f"Found {len(json_files)} JSON files")
    
    for json_file in tqdm(json_files, desc="Loading files"):
        with open(json_file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            parsed = json.loads(content)
            
            # Check if wrapped in "data" key
            if isinstance(parsed, dict) and 'data' in parsed:
                parsed = parsed['data']
            
            # Convert to list if single object
            if isinstance(parsed, dict):
                records = [parsed]
            elif isinstance(parsed2, list):
                records = parsed
            else:
                print(f"Warning: Unexpected JSON structure in {json_file.name}")
        
        # Add filename to each record
        filename = json_file.stem  
        for record in records:
            record['source_file_id'] = filename
        
        all_records.extend(records)
    
    df = pd.DataFrame(all_records)
    
    print(f"Total records after cleaning: {len(df)}")
    return df
```

```{python}
# load the data
BIO_RAW_DIR = Path("data/raw/BioguideProfiles")
bio_df = load_all_bioguide_files(BIO_RAW_DIR)
```

## Cleaning

```{python}
# check column name
bio_df.columns
```

### Missing Data

```{python}
# check na
print(f"{bio_df['usCongressBioId'].isna().sum()} files have invalid data.")

# clean invalid records
if bio_df['usCongressBioId'].isna().sum() > 0 :
   bio_df = bio_df[bio_df['usCongressBioId'].notna()]
```

### save temporary data

```{python}
bio_df.to_pickle(TEMP_DIR / 'bioguide_raw.pkl')
print(f"\nSaved raw data to {TEMP_DIR / 'bioguide_raw.pkl'}")
```

### Renaming variables

```{python}
# in case connection is lost 
# bio_df = 
```

## Creating new variables : unpack nested information

### Jobs

```{python}
type(bio_df['jobPositions'].iloc[0])
```

jobPositions variable is a list of dictionary

```{python}
# %% Parse Job Positions
# """
# Bioguide Data Processing Pipeline - Part 2: Job Positions
# ==========================================================
# Extract congressional roles, sessions, parties, and states
# """

# import json
# import pandas as pd
# import numpy as np
# from pathlib import Path
# from tqdm import tqdm

# # Load saved data
# TEMP_DIR = Path("data/temp")
# bioguide_df = pd.read_pickle(TEMP_DIR / 'bioguide_raw.pkl')
# print(f"Loaded {len(bioguide_df)} records")

# %% Parse Job Positions Function

def parse_job_positions(bioguide_df: pd.DataFrame) -> pd.DataFrame:
    """
    Extract and parse job positions from jobPositions field.
    
    Parameters
    ----------
    bioguide_df : pd.DataFrame
        Raw bioguide data with jobPositions field
        
    Returns
    -------
    pd.DataFrame
        Job-level data (id - congress session) with extracted fields
    """
    jobs_data = []
    
    for idx, row in tqdm(bioguide_df.iterrows(), 
                         total=len(bioguide_df), 
                         desc="Parsing job positions"):
        bioguide_id = row['bioguide_id']
        job_positions = row.get('jobPositions', [])
        
        # Skip if no jobs
        if not job_positions or job_positions == '[]':
            continue
        
        # Handle case where jobPositions is a string
        if isinstance(job_positions, str):
            try:
                job_positions = json.loads(job_positions)
            except:
                continue
        
        # Parse each job
        for job in job_positions:
            if not isinstance(job, dict):
                continue
                
            job_info = job.get('job', {})
            congress_aff = job.get('congressAffiliation', {})
            congress_info = congress_aff.get('congress', {})
            party_info = congress_aff.get('partyAffiliation', [])
            represents_info = congress_aff.get('represents', {})
            
            # Extract fields
            job_record = {
                'bioguide_id': bioguide_id,
                'jobname': job_info.get('name'),
                'jobtype': job_info.get('jobType'),
                'congress': congress_info.get('congressNumber'),
                'congress_start': congress_info.get('startDate'),
                'congress_end': congress_info.get('endDate'),
                'party': party_info[0].get('party', {}).get('name') if party_info else None,
                'state': represents_info.get('regionCode'),
                'region_type': represents_info.get('regionType')
            }
            
            jobs_data.append(job_record)
    
    df_jobs = pd.DataFrame(jobs_data)
    
    # Add derived variables
    df_jobs['position'] = df_jobs.apply(
        lambda x: 'senate' if x['jobtype'] == 'CongressMemberJob' and x['jobname'] == 'Senator'
                  else 'house' if x['jobtype'] == 'CongressMemberJob' 
                  else None,
        axis=1
    )
    
    df_jobs['job_other'] = (df_jobs['jobtype'] == 'OtherJob').astype(int)
    df_jobs['job_congress'] = (df_jobs['jobtype'] != 'OtherJob').astype(int)
    df_jobs['position_house'] = (df_jobs['position'] == 'house').astype(int)
    df_jobs['position_senate'] = (df_jobs['position'] == 'senate').astype(int)
    df_jobs['election_year'] = df_jobs['congress'] * 2 + 1786
    
    print(f"\nParsed {len(df_jobs)} job records from {df_jobs['bioguide_id'].nunique()} members")
    print(f"\nJob types:\n{df_jobs['jobtype'].value_counts()}")
    
    return df_jobs
```

```{python}
# %% Apply Manual Corrections

def apply_manual_corrections(df_jobs: pd.DataFrame) -> pd.DataFrame:
    """Apply manual corrections for known data issues."""
    
    # Add John Peter Ricketts (R000618) - missing in original data
    if 'R000618' not in df_jobs['bioguide_id'].values:
        ricketts_record = pd.DataFrame([{
            'bioguide_id': 'R000618',
            'jobname': 'Senator',
            'jobtype': 'CongressMemberJob',
            'congress': 118,
            'state': 'NE',
            'party': 'Republican',
            'position': 'senate',
            'job_other': 0,
            'job_congress': 1,
            'position_house': 0,
            'position_senate': 1,
            'election_year': 2022
        }])
        df_jobs = pd.concat([df_jobs, ricketts_record], ignore_index=True)
        print("Added missing record: R000618 (John Ricketts)")
    
    # Fix missing party for K000200 (70th congress)
    mask = (df_jobs['bioguide_id'] == 'K000200') & (df_jobs['congress'] == 70)
    if mask.any():
        df_jobs.loc[mask, 'party'] = 'Republican'
        print("Fixed party for K000200 (70th congress)")
    
    # Fix missing state for S000566 (8th congress Representative)
    mask = ((df_jobs['bioguide_id'] == 'S000566') & 
            (df_jobs['congress'] == 8) & 
            (df_jobs['jobname'] == 'Representative'))
    if mask.any():
        df_jobs.loc[mask, 'state'] = 'NY'
        print("Fixed state for S000566 (8th congress)")
    
    return df_jobs
```

```{python}
# %% Execute Parsing

df_jobs = parse_job_positions(bioguide_df)
df_jobs = apply_manual_corrections(df_jobs)

# Inspect results
print("\n" + "="*60)
print("JOB POSITIONS SUMMARY")
print("="*60)
print(f"Total job records: {len(df_jobs):,}")
print(f"Unique members: {df_jobs['bioguide_id'].nunique():,}")
print(f"\nCongress range: {df_jobs['congress'].min():.0f} - {df_jobs['congress'].max():.0f}")
print(f"\nPosition breakdown:")
print(df_jobs['position'].value_counts())
print(f"\nParty breakdown (top 5):")
print(df_jobs['party'].value_counts().head())
```

```{python}
# Save
df_jobs.to_pickle(TEMP_DIR / 'df_jobs.pkl')
df_jobs.to_csv(TEMP_DIR / 'df_jobs.csv', index=False)
print(f"\nSaved to {TEMP_DIR / 'df_jobs.pkl'}")
```

### Relationships (Kinship)

```{python}
bio_df['isrelated'] = bio_df.assgin(
    bio_df['relationship'] lambda x: len(x) > 0
)
```

### Profiles